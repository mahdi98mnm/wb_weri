{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "import pickle\n",
    "import xarray as xr\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from google.colab import files\n",
    "import calendar\n",
    "\n",
    "import multiprocessing\n",
    "pool = multiprocessing.Pool(processes=64)\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# set coordinate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAT_MIN = 25\n",
    "LAT_MAX = 45\n",
    "LON_MIN = -125\n",
    "LON_MAX = -65"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create List Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Don't run - this code ran for list of files P, Temp, Tmax, Tmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = \"Daily\"\n",
    "time = \"Past\"\n",
    "para = [\n",
    "    \"P\",\n",
    "    # \"LWd\",\n",
    "    # \"Pres\",\n",
    "    # \"RelHum\",\n",
    "    # \"SpecHum\",\n",
    "    # \"SWd\",\n",
    "    \"Temp\",\n",
    "    \"Tmax\",\n",
    "    \"Tmin\",\n",
    "    # \"Wind\",\n",
    "]\n",
    "\n",
    "result = {}\n",
    "\n",
    "for p in para:\n",
    "    filesFolder = os.path.abspath(f\"/content/drive/MyDrive/w/{time}/{p}/{step}\")\n",
    "    filesList = os.listdir(filesFolder)\n",
    "    filesPath = [f\"{filesFolder}/{i}\" for i in filesList]\n",
    "    result[f\"{p}\"] = filesPath\n",
    "\n",
    "with open(f'/content/drive/MyDrive/w/FilesList.pkl', 'wb') as f:\n",
    "    pickle.dump(result, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read list of files from drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'/content/drive/MyDrive/w/FilesList.pkl', 'rb') as f:\n",
    "    filesList = pickle.load(f)\n",
    "\n",
    "filesList = {key : sorted(filesList[key]) for key in sorted(filesList)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# function for mask netcdf files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_nc_file(\n",
    "    nc\n",
    "):\n",
    "\n",
    "    with xr.open_dataset(nc) as xr_nc:\n",
    "\n",
    "        result = xr_nc.sel(\n",
    "            lat = slice(LAT_MAX, LAT_MIN),\n",
    "            lon = slice(LON_MIN, LON_MAX),\n",
    "        )\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate list of cumulative days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cumulative_days(start_year, end_year):\n",
    "    cumulative_days_list = [0]\n",
    "\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        if calendar.isleap(year):\n",
    "            days_in_year = 366\n",
    "        else:\n",
    "            days_in_year = 365\n",
    "\n",
    "        cumulative_days_list.append(days_in_year)\n",
    "\n",
    "\n",
    "\n",
    "    return cumulative_days_list\n",
    "\n",
    "start_year = 1979\n",
    "end_year = 2023\n",
    "result = cumulative_days(start_year, end_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# calculate cumulative days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cumulative_list(input_list):\n",
    "    return [sum(input_list[:i+1]) for i in range(len(input_list))]\n",
    "\n",
    "number_of_days = calculate_cumulative_list(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# download data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Temp\", \":\", number_of_days)\n",
    "\n",
    "for j, jj in enumerate(number_of_days):\n",
    "\n",
    "    if jj != len(filesList[\"Temp\"]):\n",
    "\n",
    "        print(f\"Para: Temp, N: {j}, number_of_days:{number_of_days[j]}, number_of_days+1: {number_of_days[j+1]}\")\n",
    "\n",
    "        result_list = map(mask_nc_file, filesList[\"Temp\"][number_of_days[j]:number_of_days[j+1]])\n",
    "\n",
    "        result_concat = xr.concat(result_list, dim='time')\n",
    "\n",
    "        with open(f'/content/drive/MyDrive/w/Data_Temp/{\"Temp\"}-{j}.pkl', 'wb') as f:\n",
    "\n",
    "            pickle.dump(result_concat, f)\n",
    "\n",
    "        del result_list\n",
    "\n",
    "        del result_concat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compress tmean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Directory containing the files to download\n",
    "directory = \"/content/drive/MyDrive/w/Data_Temp\"\n",
    "\n",
    "# Get all files in the directory\n",
    "files_list = os.listdir(directory)\n",
    "\n",
    "# Compress the files into a ZIP archive\n",
    "zip_filename = \"files_Temp.zip\"\n",
    "zip_filepath = os.path.join(directory, zip_filename)\n",
    "os.system(f\"zip -r {zip_filepath} {directory}\")\n",
    "\n",
    "# Download the ZIP archive\n",
    "files.download(zip_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### maximum temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tmax\", \":\", number_of_days)\n",
    "\n",
    "for j, jj in enumerate(number_of_days):\n",
    "\n",
    "    if jj != len(filesList[\"Tmax\"]):\n",
    "\n",
    "        print(f\"Para: Tmax, N: {j}, number_of_days:{number_of_days[j]}, number_of_days+1: {number_of_days[j+1]}\")\n",
    "\n",
    "        result_list = map(mask_nc_file, filesList[\"Tmax\"][number_of_days[j]:number_of_days[j+1]])\n",
    "\n",
    "        result_concat = xr.concat(result_list, dim='time')\n",
    "\n",
    "        with open(f'/content/drive/MyDrive/w/Data_Tmax/{\"Tmax\"}-{j}.pkl', 'wb') as f:\n",
    "\n",
    "            pickle.dump(result_concat, f)\n",
    "\n",
    "        del result_list\n",
    "\n",
    "        del result_concat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compress tmax data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing the files to download\n",
    "directory = \"/content/drive/MyDrive/w/Data_Tmax\"\n",
    "\n",
    "# Get all files in the directory\n",
    "files_list = os.listdir(directory)\n",
    "\n",
    "# Compress the files into a ZIP archive\n",
    "zip_filename = \"files_Tmax.zip\"\n",
    "zip_filepath = os.path.join(directory, zip_filename)\n",
    "os.system(f\"zip -r {zip_filepath} {directory}\")\n",
    "\n",
    "# Download the ZIP archive\n",
    "files.download(zip_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### minimum temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tmin\", \":\", number_of_days)\n",
    "\n",
    "for j, jj in enumerate(number_of_days):\n",
    "\n",
    "    if jj != len(filesList[\"Tmin\"]):\n",
    "\n",
    "        print(f\"Para: Tmin, N: {j}, number_of_days:{number_of_days[j]}, number_of_days+1: {number_of_days[j+1]}\")\n",
    "\n",
    "        result_list = map(mask_nc_file, filesList[\"Tmin\"][number_of_days[j]:number_of_days[j+1]])\n",
    "\n",
    "        result_concat = xr.concat(result_list, dim='time')\n",
    "\n",
    "        with open(f'/content/drive/MyDrive/w/Data_Tmin/{\"Tmin\"}-{j}.pkl', 'wb') as f:\n",
    "\n",
    "            pickle.dump(result_concat, f)\n",
    "\n",
    "        del result_list\n",
    "\n",
    "        del result_concat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compress tmin data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing the files to download\n",
    "directory = \"/content/drive/MyDrive/w/Data_Tmin\"\n",
    "\n",
    "# Get all files in the directory\n",
    "files_list = os.listdir(directory)\n",
    "\n",
    "# Compress the files into a ZIP archive\n",
    "zip_filename = \"files_Tmin.zip\"\n",
    "zip_filepath = os.path.join(directory, zip_filename)\n",
    "os.system(f\"zip -r {zip_filepath} {directory}\")\n",
    "\n",
    "# Download the ZIP archive\n",
    "files.download(zip_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"P\", \":\", number_of_days)\n",
    "\n",
    "for j, jj in enumerate(number_of_days):\n",
    "\n",
    "    if jj != len(filesList[\"P\"]):\n",
    "\n",
    "        print(f\"Para: P, N: {j}, number_of_days:{number_of_days[j]}, number_of_days+1: {number_of_days[j+1]}\")\n",
    "\n",
    "        result_list = map(mask_nc_file, filesList[\"P\"][number_of_days[j]:number_of_days[j+1]])\n",
    "\n",
    "        result_concat = xr.concat(result_list, dim='time')\n",
    "\n",
    "        with open(f'/content/drive/MyDrive/w/Data_P/{\"P\"}-{j}.pkl', 'wb') as f:\n",
    "\n",
    "            pickle.dump(result_concat, f)\n",
    "\n",
    "        del result_list\n",
    "\n",
    "        del result_concat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compress P data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing the files to download\n",
    "directory = \"/content/drive/MyDrive/w/Data_P\"\n",
    "\n",
    "# Get all files in the directory\n",
    "files_list = os.listdir(directory)\n",
    "\n",
    "# Compress the files into a ZIP archive\n",
    "zip_filename = \"files_P.zip\"\n",
    "zip_filepath = os.path.join(directory, zip_filename)\n",
    "os.system(f\"zip -r {zip_filepath} {directory}\")\n",
    "\n",
    "# Download the ZIP archive\n",
    "files.download(zip_filepath)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
